{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-24T17:46:47.032395Z","iopub.execute_input":"2021-11-24T17:46:47.032666Z","iopub.status.idle":"2021-11-24T17:46:50.598662Z","shell.execute_reply.started":"2021-11-24T17:46:47.032636Z","shell.execute_reply":"2021-11-24T17:46:50.597967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\ndataset_dir = '/kaggle/input/dataset-foglie/training'\n\nlabels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']\n\n#%%script false --no-raise-error\nnum_row = len(labels)//2\nnum_col = len(labels)//num_row\nfig, axes = plt.subplots(num_row, num_col, figsize=(2*num_row,15*num_col))\nfor i in range(len(labels)):\n  if i < len(labels):\n    class_imgs = next(os.walk('{}/{}/'.format(dataset_dir, labels[i])))[2]\n    class_img = class_imgs[0]\n    img = Image.open('{}/{}/{}'.format(dataset_dir, labels[i], class_img))\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(np.array(img))\n    ax.set_title('{}'.format(labels[i]))\nplt.tight_layout()\nplt.show()\n\nSEED = 19011997\nSPLIT = 0.2\nBATCH_SIZE = 128\nIMG_SIZE = (256,256)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:46:50.600481Z","iopub.execute_input":"2021-11-24T17:46:50.60073Z","iopub.status.idle":"2021-11-24T17:46:53.326679Z","shell.execute_reply.started":"2021-11-24T17:46:50.600695Z","shell.execute_reply":"2021-11-24T17:46:53.324367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pathlib\n\ndataset_dir_path = pathlib.Path(dataset_dir)\nimages_count_total = len(list(dataset_dir_path.glob('*/*.jpg')))\nprint('Total count: {}'.format(images_count_total))\nimages_count = {}\nfor label in labels:\n    count = len(list(dataset_dir_path.glob('{}/*.jpg'.format(label))))\n    images_count[label] = count\n    print('{} count: {}'.format(label, count))\nplt.figure(figsize=(16,4))\nplt.bar(range(len(labels)), list(images_count.values()))\nplt.xticks(range(len(labels)), labels)\nplt.title('Dataset distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:46:53.32783Z","iopub.execute_input":"2021-11-24T17:46:53.328226Z","iopub.status.idle":"2021-11-24T17:46:53.699775Z","shell.execute_reply.started":"2021-11-24T17:46:53.328193Z","shell.execute_reply":"2021-11-24T17:46:53.699108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_class = max(images_count.values())\nclass_weights = {}\ni = 0\nfor k,v in images_count.items():\n    class_weights[i] = max_class/v\n    i += 1\nprint(class_weights)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:46:53.70086Z","iopub.execute_input":"2021-11-24T17:46:53.701229Z","iopub.status.idle":"2021-11-24T17:46:53.707787Z","shell.execute_reply.started":"2021-11-24T17:46:53.701192Z","shell.execute_reply":"2021-11-24T17:46:53.706975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ndef import_dataset(subset):\n    return tf.keras.preprocessing.image_dataset_from_directory(\n        dataset_dir,\n        labels='inferred',\n        label_mode='categorical',\n        class_names=labels,\n        color_mode='rgb',\n        batch_size=BATCH_SIZE,\n        image_size=IMG_SIZE,\n        shuffle=True,\n        seed=SEED,\n        validation_split=SPLIT,\n        subset=subset,\n        interpolation='bilinear',\n        follow_links=False,\n        crop_to_aspect_ratio=False\n    )\n\ndataset_training = import_dataset('training')\ndataset_validation = import_dataset('validation')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:46:53.709784Z","iopub.execute_input":"2021-11-24T17:46:53.710654Z","iopub.status.idle":"2021-11-24T17:46:54.693947Z","shell.execute_reply.started":"2021-11-24T17:46:53.710614Z","shell.execute_reply":"2021-11-24T17:46:54.693209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, onehot in dataset_training.take(1):\n  for i in range(6):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    index = np.argmax(np.array(onehot[i]), axis=0)\n    plt.title(labels[index])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:46:54.696131Z","iopub.execute_input":"2021-11-24T17:46:54.696646Z","iopub.status.idle":"2021-11-24T17:46:56.29084Z","shell.execute_reply.started":"2021-11-24T17:46:54.696602Z","shell.execute_reply":"2021-11-24T17:46:56.290153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential(\n    [\n        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n        tf.keras.layers.RandomRotation(0.4, fill_mode='constant'), # oppure \"nearest\"\n         tf.keras.layers.RandomRotation(0.7, fill_mode='constant'),\n        tf.keras.layers.RandomZoom(\n    height_factor=(0.2,0.2), width_factor=(-0.2,-0.2), fill_mode='constant',\n    interpolation='bilinear', seed=None, fill_value=0.0),\n        tf.keras.layers.RandomZoom(\n    height_factor=(-0.2,-0.2), width_factor=(0.1,0.1), fill_mode='constant',\n    interpolation='bilinear', seed=None, fill_value=0.0),\n         tf.keras.layers.Cropping2D(cropping=((3, 3), (10, 10)), data_format=None)\n    ]\n)\nplt.figure(figsize=(10, 10))\nfor images, _ in dataset_training.take(1):\n  for i in range(6):\n    augim = data_augmentation(images)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augim[i].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:46:56.292172Z","iopub.execute_input":"2021-11-24T17:46:56.292607Z","iopub.status.idle":"2021-11-24T17:46:58.29787Z","shell.execute_reply.started":"2021-11-24T17:46:56.292572Z","shell.execute_reply":"2021-11-24T17:46:58.297132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model(input_shape, num_classes):\n    inputs = tf.keras.Input(shape=input_shape)\n    tf.keras.layers.Rescaling(1./255)\n    x = data_augmentation(inputs)\n\n    x = tf.keras.layers.Conv2D(32, 3, padding='valid')(x)\n    x = tf.keras.layers.Activation('relu')(x)\n\n    x = tf.keras.layers.Conv2D(64, 3, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization(\n    axis=1,\n    momentum=0.90,\n    epsilon=0.001,\n    center=True,\n    scale=True,\n    beta_initializer=\"zeros\",\n    gamma_initializer=\"ones\",\n    moving_mean_initializer=\"zeros\",\n    moving_variance_initializer=\"ones\",\n    beta_regularizer=None,\n    gamma_regularizer=None,\n    beta_constraint=None,\n    gamma_constraint=None)(x)\n    x = tf.keras.layers.AvgPool2D(2)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n\n    x = tf.keras.layers.Conv2D(128, 3, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization(\n    axis=1,\n    momentum=0.90,\n    epsilon=0.001,\n    center=True,\n    scale=True,\n    beta_initializer=\"zeros\",\n    gamma_initializer=\"ones\",\n    moving_mean_initializer=\"zeros\",\n    moving_variance_initializer=\"ones\",\n    beta_regularizer=None,\n    gamma_regularizer=None,\n    beta_constraint=None,\n    gamma_constraint=None)(x)\n    x = tf.keras.layers.AvgPool2D(2)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n\n    x = tf.keras.layers.Conv2D(256, 3, padding='same')(x)\n    x = tf.keras.layers.MaxPool2D(2)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    \n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(128, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    x = tf.keras.layers.Dense(64, activation='relu')(x)\n\n    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n    return tf.keras.Model(inputs, outputs)\nmodel = make_model(IMG_SIZE + (3,), len(labels))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:46:58.299275Z","iopub.execute_input":"2021-11-24T17:46:58.299772Z","iopub.status.idle":"2021-11-24T17:46:58.875003Z","shell.execute_reply.started":"2021-11-24T17:46:58.299735Z","shell.execute_reply":"2021-11-24T17:46:58.874333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 50\n#physical_devices = tf.config.list_physical_devices('GPU')\n#print(physical_devices)\npatience = 25\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"./ckp_best3.h5\", save_best_only=True),\n    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience),\n]\nmodel = tf.keras.models.load_model('/kaggle/input/checkp2/ckp_best2.h5')\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-3),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\",\"mse\"],\n)\nmodel.fit(\n    dataset_training, epochs=EPOCHS, callbacks=callbacks, validation_data=dataset_validation, class_weight=class_weights\n\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:46:58.876473Z","iopub.execute_input":"2021-11-24T17:46:58.876719Z","iopub.status.idle":"2021-11-24T18:24:03.247921Z","shell.execute_reply.started":"2021-11-24T17:46:58.876685Z","shell.execute_reply":"2021-11-24T18:24:03.247184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save(\"./ckp_best3.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:24:03.249274Z","iopub.execute_input":"2021-11-24T18:24:03.249554Z","iopub.status.idle":"2021-11-24T18:24:03.254066Z","shell.execute_reply.started":"2021-11-24T18:24:03.249517Z","shell.execute_reply":"2021-11-24T18:24:03.252942Z"},"trusted":true},"execution_count":null,"outputs":[]}]}